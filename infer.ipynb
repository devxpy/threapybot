{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da7c2bf0-2bde-4896-bf95-11efa119ba90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adapter_config.json  checkpoint-1400  README.md\n",
      "adapter_model.bin    checkpoint-500   special_tokens_map.json\n",
      "checkpoint-1000      checkpoint-600   tokenizer_config.json\n",
      "checkpoint-1100      checkpoint-700   tokenizer.json\n",
      "checkpoint-1200      checkpoint-800   tokenizer.model\n",
      "checkpoint-1300      checkpoint-900   training_args.bin\n"
     ]
    }
   ],
   "source": [
    "!ls output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09d823a0-afdd-43eb-a356-47cd6168c98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/therapybot/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-10 13:57:27,411] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import TextStreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f107fba-f363-4e9b-beab-718c3c50eeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.31s/it]\n",
      "Downloading (…)/adapter_config.json: 100%|██████████| 447/447 [00:00<00:00, 72.9kB/s]\n",
      "Downloading adapter_model.bin: 100%|██████████| 67.2M/67.2M [00:01<00:00, 53.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "base_model_name = 'meta-llama/Llama-2-7b-hf'\n",
    "# ft_model_name = \"./output/\"\n",
    "ft_model_name = \"devxpy/therapybot\"\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_8bit=False,\n",
    "        load_in_4bit=True,\n",
    "    ),\n",
    "    device_map = {\"\": 0},\n",
    "    torch_dtype = torch.bfloat16,\n",
    "    # torch_dtype = torch.float16,\n",
    "    trust_remote_code = True,\n",
    ")\n",
    "ftmodel = PeftModel.from_pretrained(base_model, ft_model_name, torch_dtype=torch.float16,)\n",
    "# ftmodel.push_to_hub(\"devxpy/therapybot\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2044ab95-d037-4a28-bad5-f4d0b24b17bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ftmodel.push_to_hub(\"devxpy/therapybot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42b01777-a368-4629-8f48-9dcb56a57b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://embed.spotify.com/?uri=spotify:playlist:3Fv3vd2eqb9rVvIJcJxEoU',\n",
       " 'https://embed.spotify.com/?uri=spotify:playlist:2uM2IvAqc6HZmEiRjJBF6Q',\n",
       " 'https://embed.spotify.com/?uri=spotify:playlist:54j0DPxOen62HcPCc2Pmoe',\n",
       " 'https://embed.spotify.com/?uri=spotify:playlist:1uN3iCLmAXg6rmS86SJM7g',\n",
       " 'https://embed.spotify.com/?uri=spotify:playlist:703bHAXaUiMA90jlQyemQb',\n",
       " 'https://embed.spotify.com/?uri=spotify:playlist:4uLg82FvdD0blplTBTmR59',\n",
       " 'https://embed.spotify.com/?uri=spotify:playlist:4SJlsd4gR9A8DTzRoMrFPl',\n",
       " 'https://embed.spotify.com/?uri=spotify:playlist:4pJ4ZEzj93WnpU4CUgVxH1',\n",
       " 'https://embed.spotify.com/?uri=spotify:playlist:0QrUMIfELgl7gi1zYcCgq4']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from qdrant_client import QdrantClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "\n",
    "COLLECTION_NAME = \"spotify-genres\"\n",
    "\n",
    "encoder = SentenceTransformer(\n",
    "    \"thenlper/gte-large\", device=\"mps\" if torch.has_mps else \"cuda\"\n",
    ")  # thenlper/gte-base\n",
    "\n",
    "\n",
    "def get_playlists(q, limit=9):\n",
    "    # Create a client object for Qdrant.\n",
    "    qdrant = QdrantClient(\n",
    "        \"https://303757f4-9127-4df0-a9e8-9669f997f742.us-east4-0.gcp.cloud.qdrant.io:6333\",\n",
    "        api_key=os.environ['QDRANT_API_KEY'],\n",
    "    )\n",
    "    hits = qdrant.search(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        query_vector=encoder.encode(q).tolist(),\n",
    "        limit=limit,\n",
    "    )\n",
    "    return [x.payload[\"playlist_url\"] for x in hits]\n",
    "\n",
    "get_playlists(\"sad and angry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90dbdaa6-f96c-4f96-8a0c-584bdf5c1996",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT =  \"\"\"\n",
    "The following is a transcript between a human and a helpful assistant who's trying to trying to use Acceptance and commitment therapy to help the Human.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6f17b1c-c354-4416-8e27-fad08a62b407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Hey! i am having trouble focusing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay that sounds like something I can definitely help with. What exactly do you mean by \"having trouble focusing\"? Are you struggling with concentration or focus on specific tasks? Or perhaps you find yourself easily distracted in general? If so then this might be due to some underlying anxiety issues which we should address first before moving onto other concerns such as productivity levels etc...\n",
      "Try relaxation techniques e.g breathing exercises, meditation etc.. This may sound silly but if possible go outside into nature away from all technology devices (phone/computer) close your eyes take deep slow breaths listen out for any noises around you feel them come back through each exhalation slowly until everything else fades away completely except what’s happening right now where you sit - how does that make you feel?\n",
      "\n",
      "https://embed.spotify.com/?uri=spotify:playlist:6fzw3GiLktfRKczD6sl6mT https://embed.spotify.com/?uri=spotify:playlist:4s0siSTRtglRvQKxpWJ6pM\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  I get easily distracted \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there anything particular about certain situations when this happens more often than others? For example maybe while working at home alone without interruptions? Perhaps even listening music helps keep things focused enough not too much though lol don’t wanna overdo it either ;)\n",
      "set up routine & rituals sticky notes reminders alarms whatever works for u - just remember why ur doing these activities because they serve purpose rather than being chores themselves :) Good luck! Feel free ask me again whenever needed <3\n",
      "\n",
      "https://embed.spotify.com/?uri=spotify:playlist:4s0siSTRtglRvQKxpWJ6pM https://embed.spotify.com/?uri=spotify:playlist:6fzw3GiLktfRKczD6sl6mT\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  \n"
     ]
    }
   ],
   "source": [
    "def get_prompt(messages, prompt):\n",
    "    ret = f\"### Human: <s><<SYS>>\\n{SYSTEM_PROMPT}\\n<</SYS>></s>\"\n",
    "    for role, content in messages:\n",
    "        ret += f\"\\n### {role}: <s>{content}</s>\"\n",
    "    ret += f\"\\n### Assistant: <s>{prompt.strip()}\"    \n",
    "    return ret\n",
    "\n",
    "class MyTextStreamer(TextStreamer):\n",
    "    def on_finalized_text(self, text: str, stream_end: bool = False):\n",
    "        text = text.rstrip(self.tokenizer.eos_token)\n",
    "        return super().on_finalized_text(text, stream_end)\n",
    "    \n",
    "streamer = MyTextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "history = [\n",
    "    (\"Human\", \"Hey!\"),\n",
    "    (\"Assistant\", \"Hello there! How are you today?\\nIf you are looking for advice from an AI, please state your problem clearly. I will try my best to solve it.\"),\n",
    "]\n",
    "while True:\n",
    "    print()\n",
    "    \n",
    "    msg = input(\">> \").strip()\n",
    "    if not msg:\n",
    "        break\n",
    "    history.append((\"Human\", msg))\n",
    "    response = \"\"\n",
    "    \n",
    "    for prompt in [\"\", \"Advice: \"]:\n",
    "        prompt = get_prompt(history, response + \" \" + prompt)\n",
    "        inputs = tokenizer.encode(prompt, return_tensors=\"pt\", add_special_tokens=False)\n",
    "        generated = ftmodel.generate(\n",
    "            input_ids=inputs,\n",
    "            streamer=streamer,\n",
    "            repetition_penalty=1.2,\n",
    "            max_new_tokens=1024,\n",
    "            temperature=0.5,\n",
    "            top_p=0.95,\n",
    "            top_k=40,\n",
    "            do_sample=True,\n",
    "            use_cache=True,\n",
    "        )\n",
    "        response += \" \" + tokenizer.decode(generated[0][len(inputs[0]):]).strip(\"</s>\").strip()\n",
    "    history.append((\"Assistant\", response.strip()))\n",
    "\n",
    "    print()\n",
    "    print(\" \".join(get_playlists(msg, 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
